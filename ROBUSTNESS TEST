# Experiment 03 â€” Prompt Robustness Under Slang, Typos, and Corrupt Input

**Goal:** Evaluate how well the LLM interprets intent when instructions are degraded.

---

## ğŸ§ª Inputs Tested
- â€œr3wr1te th1s professonal plzâ€
- â€œRewrite like im at work but dont change meaning okâ€
- â€œfix??grammer this textâ€
- Versions with emojis + broken unicode blocks

---

## ğŸ“Œ Results

### Strengths:
- Always understood â€œrewriteâ€ intent  
- Corrected obvious errors  
- Resistant to alphanumeric substitutions

### Weaknesses:
- Unicode blocks confused layout  
- Emojis sometimes caused missing segments  
- Double punctuation led to partial rewrites

---

## ğŸ Reproducible Bug
Prompts containing mixed Unicode (emoji + glitch symbols) produced incomplete rewrites in 6/10 tests.

---

## ğŸ§  Insight
Model is robust with language corruption but brittle with **formatting corruption**.
